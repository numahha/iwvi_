{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdec0e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toru.hishinuma\\anaconda3\\envs\\note\\lib\\site-packages\\gym\\spaces\\box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import custom_gym\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "env = gym.make('CustomPendulum-v0')\n",
    "s_dim = env.reset().shape[0]\n",
    "a_dim = env.action_space.sample().shape[0]\n",
    "print(s_dim,a_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74a553b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 200, 8])\n"
     ]
    }
   ],
   "source": [
    "offline_data = np.load('np_offline_data.npy')\n",
    "offline_data = torch.from_numpy(offline_data.astype(np.float32)).clone()\n",
    "print(offline_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aefacd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapoint2sads(datapoint):\n",
    "    s = datapoint[: s_dim]\n",
    "    a = datapoint[s_dim : (s_dim+a_dim)]\n",
    "    #ds = datapoint[(s_dim+a_dim) : (2*s_dim+a_dim)] - s\n",
    "    ds = datapoint[(s_dim+a_dim) : (2*s_dim+a_dim)]\n",
    "    return s,a,ds\n",
    "\n",
    "def gaussian_likelihood_loss(y, mu, logvar):\n",
    "    # 分散行列Varが対角成分var_iの対角行列の場合には、log(det|Var|) = log(prod_i var_i) = sum_i log(var_i) \n",
    "    return 0.5 * torch.mean(((y-mu)**2) * torch.exp(-logvar) + logvar)\n",
    "\n",
    "\n",
    "def kld(mu1, logvar1, mu2, logvar2):\n",
    "    # kld(p1|p2) = E_{z~p1}[ log p1(z) - log p2(z) ]\n",
    "    tmp1 = 0.5 * (logvar2 - logvar1) # log (sigma2/sigma1)\n",
    "    tmp2 = 0.5*(torch.exp(logvar1)+(mu1-mu2)**2) / torch.exp(logvar2) # (sigma1^2+(mu1-mu2)^2)/(2*sigma2^2)\n",
    "    return torch.mean(tmp1 + tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2862753",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = s_dim+a_dim\n",
    "y_dim = s_dim\n",
    "z_dim = 1\n",
    "g_dim = 1\n",
    "#f_phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86aa1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, s_dim, a_dim, z_dim, g_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.net_f = torch.nn.Sequential(\n",
    "                            torch.nn.Linear(2*s_dim+a_dim, 64),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(64, g_dim),\n",
    "                            )\n",
    "        self.net_q = torch.nn.Sequential(\n",
    "                            torch.nn.Linear(g_dim, 64),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(64, 2*z_dim),\n",
    "                            )\n",
    "\n",
    "    def forward(self, data_m):\n",
    "        g_m = self.net_f(data_m).mean().reshape(1,-1)\n",
    "        return self.net_q(g_m).flatten()\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731b5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, s_dim, a_dim, z_dim):  \n",
    "        super(Decoder, self).__init__()\n",
    "        self.net_phat = torch.nn.Sequential(\n",
    "                            torch.nn.Linear(s_dim+a_dim+z_dim, 64),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(64, 2*s_dim),\n",
    "                            )\n",
    "        \n",
    "    def forward(self, saz):\n",
    "        return self.net_phat(saz)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03fef37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class unweightedVI(torch.nn.Module):\n",
    "    def __init__(self, s_dim, a_dim, z_dim):\n",
    "        super(unweightedVI, self).__init__()\n",
    "        self.enc = Encoder(s_dim, a_dim, z_dim, g_dim)\n",
    "        self.dec = Decoder(s_dim, a_dim, z_dim)\n",
    "        self.prior = torch.nn.Parameter(torch.zeros(2*z_dim))\n",
    "        self.nu = 1e-2\n",
    "        \n",
    "\n",
    "    def loss(self, offline_data_m):\n",
    "        z_mu_logvar = self.enc(offline_data_m)\n",
    "\n",
    "        # reparametrization trick\n",
    "        eps = torch.randn_like(z_mu_logvar[:z_dim])\n",
    "        std = torch.exp(0.5 * z_mu_logvar[z_dim:])\n",
    "        z = (eps*std+z_mu_logvar[:z_dim]) * torch.ones(offline_data.shape[1],z_dim)\n",
    "\n",
    "        saz = torch.cat([offline_data[m,:,:(s_dim+a_dim)],z],dim=1)\n",
    "\n",
    "        ds_mu_logvar = self.dec(saz)\n",
    "\n",
    "        ret_loss = 0\n",
    "\n",
    "        # y = offline_data[m,:,(s_dim+a_dim):-1]\n",
    "        # mu = ds_mu_logvar[:,:s_dim]\n",
    "        # logvar = ds_mu_logvar[:,s_dim:]        \n",
    "        ret_loss += gaussian_likelihood_loss(offline_data[m,:,(s_dim+a_dim):-1],\n",
    "                                         ds_mu_logvar[:,:s_dim],\n",
    "                                         ds_mu_logvar[:,s_dim:]) # approx of E_{z~q}[ - log p(y|x,z) ]\n",
    "        \n",
    "        ret_loss += self.nu * kld(z_mu_logvar[:z_dim], \n",
    "                              z_mu_logvar[z_dim:],\n",
    "                              self.prior[:z_dim],\n",
    "                              self.prior[z_dim:]) # nu * E_{z~q}[ log q(z) - log p(z) ]\n",
    "        return ret_loss\n",
    "    \n",
    "    \n",
    "vi = unweightedVI(s_dim, a_dim, z_dim)\n",
    "\n",
    "optimizer = torch.optim.Adam(vi.parameters(),lr=0.001)\n",
    "\n",
    "for i in range(10):\n",
    "    m = np.random.randint(offline_data.shape[0])\n",
    "    optimizer.zero_grad()\n",
    "    loss = vi.loss(offline_data[m,:,:-1])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "        #m = np.random.randint(offline_data.shape[0])\n",
    "        #z_mu_logvar = enc(offline_data[m,:,:-1])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee1c5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
